{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["59JxVmJJ2Zrr"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Basic"],"metadata":{"id":"59JxVmJJ2Zrr"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88pc0Jcc2Kym","executionInfo":{"status":"ok","timestamp":1684399066213,"user_tz":-540,"elapsed":7,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"5a8ed2ef-285a-4d89-fd09-89c59dd117d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May 18 08:37:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# GPU 정보 \n","!nvidia-smi"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lov4MHBk2RSm","executionInfo":{"status":"ok","timestamp":1684399104791,"user_tz":-540,"elapsed":38581,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"7945284d-fb44-44fd-b249-b918e75ab190"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd './drive/MyDrive/Workspace/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHClblep2RVG","executionInfo":{"status":"ok","timestamp":1684399104791,"user_tz":-540,"elapsed":6,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"5f105c29-fc51-4f81-bb9b-0c699745e4a9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Workspace\n"]}]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1RHE4sS2RXr","executionInfo":{"status":"ok","timestamp":1684399104791,"user_tz":-540,"elapsed":4,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"9f3a9bdb-e820-435d-9f95-1627e35f8950"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n"]}]},{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"5vdi2fw22Xp7"}},{"cell_type":"code","source":["!pip install gluonnlp==0.9.1\n","!pip install tqdm\n","!pip install pandas\n","!pip install mxnet\n","!pip install sentencepiece"],"metadata":{"id":"panO2Pcv2RaT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684399143115,"user_tz":-540,"elapsed":31451,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"cf9af75e-6f84-427a-bee7-2c29eb51421f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gluonnlp==0.9.1\n","  Downloading gluonnlp-0.9.1.tar.gz (252 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.9.1) (1.22.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.9.1) (0.29.34)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.9.1) (23.1)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.9.1-cp310-cp310-linux_x86_64.whl size=557751 sha256=decdad8e50191cc4246c651e9f08af64a7bd71e1ffe4beb2455a12656b109f0f\n","  Stored in directory: /root/.cache/pip/wheels/fc/5b/9c/3295bb07f7c5544a96303a48988707816f44a536e8e1413922\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.22.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.27.1)\n","Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.20.1\n","    Uninstalling graphviz-0.20.1:\n","      Successfully uninstalled graphviz-0.20.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["!pip uninstall -y torchaudio\n","!pip uninstall -y torchvision\n","!pip uninstall -y torchdata\n","!pip uninstall -y torch\n","!pip uninstall -y torchtext"],"metadata":{"id":"hgDESmEt2Rc5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684399177640,"user_tz":-540,"elapsed":34538,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"27bb96a8-45f2-4500-96ef-b99be1d01b96"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torchaudio 2.0.1+cu118\n","Uninstalling torchaudio-2.0.1+cu118:\n","  Successfully uninstalled torchaudio-2.0.1+cu118\n","Found existing installation: torchvision 0.15.1+cu118\n","Uninstalling torchvision-0.15.1+cu118:\n","  Successfully uninstalled torchvision-0.15.1+cu118\n","Found existing installation: torchdata 0.6.0\n","Uninstalling torchdata-0.6.0:\n","  Successfully uninstalled torchdata-0.6.0\n","Found existing installation: torch 2.0.0+cu118\n","Uninstalling torch-2.0.0+cu118:\n","  Successfully uninstalled torch-2.0.0+cu118\n","Found existing installation: torchtext 0.15.1\n","Uninstalling torchtext-0.15.1:\n","  Successfully uninstalled torchtext-0.15.1\n"]}]},{"cell_type":"code","source":["!pip install torch\n","!pip install transformers\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","!pip install pytorch_lightning==1.2.10"],"metadata":{"id":"_2tlMzvn2Rff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684399298480,"user_tz":-540,"elapsed":120842,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"87f4eb1c-1bf3-4b92-bfcb-39f1713a95f4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.12 requires torchvision>=0.8.2, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-slgu4yzj/kobert-tokenizer_1916424388a9486096503742111b87e7\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-slgu4yzj/kobert-tokenizer_1916424388a9486096503742111b87e7\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=9c323e5e062fb750330185085751c8169ab35fb8b31f13834dd0ec74ad6273cd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ar0a6z6o/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning==1.2.10\n","  Downloading pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.9/841.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (1.22.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2.0.1)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (0.18.3)\n","Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (6.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2023.4.0)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2.12.2)\n","Collecting torchmetrics==0.2.0 (from pytorch_lightning==1.2.10)\n","  Downloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.1.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch_lightning==1.2.10) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch_lightning==1.2.10) (16.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->pytorch_lightning==1.2.10) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.2.2)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 pytorch_lightning-1.2.10 torchmetrics-0.2.0 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["!pip list"],"metadata":{"id":"iwmIt0mh3Ljq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684399299473,"user_tz":-540,"elapsed":1005,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"9c797933-ecb0-451e-d5ff-3057de9ae156"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Package                       Version\n","----------------------------- --------------------\n","absl-py                       1.4.0\n","aiohttp                       3.8.4\n","aiosignal                     1.3.1\n","alabaster                     0.7.13\n","albumentations                1.2.1\n","altair                        4.2.2\n","anyio                         3.6.2\n","appdirs                       1.4.4\n","argon2-cffi                   21.3.0\n","argon2-cffi-bindings          21.2.0\n","array-record                  0.2.0\n","arviz                         0.15.1\n","astropy                       5.2.2\n","astunparse                    1.6.3\n","async-timeout                 4.0.2\n","attrs                         23.1.0\n","audioread                     3.0.0\n","autograd                      1.5\n","Babel                         2.12.1\n","backcall                      0.2.0\n","beautifulsoup4                4.11.2\n","bleach                        6.0.0\n","blis                          0.7.9\n","blosc2                        2.0.0\n","bokeh                         2.4.3\n","branca                        0.6.0\n","build                         0.10.0\n","CacheControl                  0.12.11\n","cached-property               1.5.2\n","cachetools                    5.3.0\n","catalogue                     2.0.8\n","certifi                       2022.12.7\n","cffi                          1.15.1\n","chardet                       4.0.0\n","charset-normalizer            2.0.12\n","chex                          0.1.7\n","click                         8.1.3\n","cloudpickle                   2.2.1\n","cmake                         3.25.2\n","cmdstanpy                     1.1.0\n","colorcet                      3.0.1\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","confection                    0.0.4\n","cons                          0.4.5\n","contextlib2                   0.6.0.post1\n","contourpy                     1.0.7\n","convertdate                   2.4.0\n","cryptography                  40.0.2\n","cufflinks                     0.17.3\n","cupy-cuda11x                  11.0.0\n","cvxopt                        1.3.0\n","cvxpy                         1.3.1\n","cycler                        0.11.0\n","cymem                         2.0.7\n","Cython                        0.29.34\n","dask                          2022.12.1\n","datascience                   0.17.6\n","db-dtypes                     1.1.1\n","dbus-python                   1.2.16\n","debugpy                       1.6.6\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","distributed                   2022.12.1\n","dlib                          19.24.1\n","dm-tree                       0.1.8\n","docutils                      0.16\n","dopamine-rl                   4.0.6\n","duckdb                        0.7.1\n","earthengine-api               0.1.350\n","easydict                      1.10\n","ecos                          2.0.12\n","editdistance                  0.6.2\n","en-core-web-sm                3.5.0\n","entrypoints                   0.4\n","ephem                         4.1.4\n","et-xmlfile                    1.1.0\n","etils                         1.2.0\n","etuples                       0.3.8\n","exceptiongroup                1.1.1\n","fastai                        2.7.12\n","fastcore                      1.5.29\n","fastdownload                  0.0.7\n","fastjsonschema                2.16.3\n","fastprogress                  1.0.3\n","fastrlock                     0.8.1\n","filelock                      3.12.0\n","firebase-admin                5.3.0\n","Flask                         2.2.4\n","flatbuffers                   23.3.3\n","flax                          0.6.9\n","folium                        0.14.0\n","fonttools                     4.39.3\n","frozendict                    2.3.7\n","frozenlist                    1.3.3\n","fsspec                        2023.4.0\n","future                        0.18.3\n","gast                          0.4.0\n","GDAL                          3.3.2\n","gdown                         4.6.6\n","gensim                        4.3.1\n","geographiclib                 2.0\n","geopy                         2.3.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","gluonnlp                      0.9.1\n","google                        2.0.3\n","google-api-core               2.11.0\n","google-api-python-client      2.84.0\n","google-auth                   2.17.3\n","google-auth-httplib2          0.1.0\n","google-auth-oauthlib          1.0.0\n","google-cloud-bigquery         3.9.0\n","google-cloud-bigquery-storage 2.19.1\n","google-cloud-core             2.3.2\n","google-cloud-datastore        2.15.1\n","google-cloud-firestore        2.11.0\n","google-cloud-language         2.9.1\n","google-cloud-storage          2.8.0\n","google-cloud-translate        3.11.1\n","google-colab                  1.0.0\n","google-crc32c                 1.5.0\n","google-pasta                  0.2.0\n","google-resumable-media        2.5.0\n","googleapis-common-protos      1.59.0\n","googledrivedownloader         0.4\n","graphviz                      0.8.4\n","greenlet                      2.0.2\n","grpcio                        1.54.0\n","grpcio-status                 1.48.2\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.25.2\n","gym-notices                   0.0.8\n","h5netcdf                      1.1.0\n","h5py                          3.8.0\n","hijri-converter               2.3.1\n","holidays                      0.23\n","holoviews                     1.15.4\n","html5lib                      1.1\n","httpimport                    1.3.0\n","httplib2                      0.21.0\n","huggingface-hub               0.14.1\n","humanize                      4.6.0\n","hyperopt                      0.2.7\n","idna                          3.4\n","imageio                       2.25.1\n","imageio-ffmpeg                0.4.8\n","imagesize                     1.4.1\n","imbalanced-learn              0.10.1\n","imgaug                        0.4.0\n","importlib-resources           5.12.0\n","imutils                       0.5.4\n","inflect                       6.0.4\n","iniconfig                     2.0.0\n","intel-openmp                  2023.1.0\n","ipykernel                     5.5.6\n","ipython                       7.34.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.4.1\n","ipywidgets                    7.7.1\n","itsdangerous                  2.1.2\n","jax                           0.4.8\n","jaxlib                        0.4.7+cuda11.cudnn86\n","jieba                         0.42.1\n","Jinja2                        3.1.2\n","joblib                        1.2.0\n","jsonpickle                    3.0.1\n","jsonschema                    4.3.3\n","jupyter-client                6.1.12\n","jupyter-console               6.1.0\n","jupyter_core                  5.3.0\n","jupyter-server                1.24.0\n","jupyterlab-pygments           0.2.2\n","jupyterlab-widgets            3.0.7\n","kaggle                        1.5.13\n","keras                         2.12.0\n","kiwisolver                    1.4.4\n","kobert-tokenizer              0.1\n","korean-lunar-calendar         0.3.1\n","langcodes                     3.3.0\n","lazy_loader                   0.2\n","libclang                      16.0.0\n","librosa                       0.10.0.post2\n","lightgbm                      3.3.5\n","lit                           16.0.3\n","llvmlite                      0.39.1\n","locket                        1.0.0\n","logical-unification           0.4.5\n","LunarCalendar                 0.0.9\n","lxml                          4.9.2\n","Markdown                      3.4.3\n","markdown-it-py                2.2.0\n","MarkupSafe                    2.1.2\n","matplotlib                    3.7.1\n","matplotlib-inline             0.1.6\n","matplotlib-venn               0.11.9\n","mdurl                         0.1.2\n","miniKanren                    1.0.3\n","missingno                     0.5.2\n","mistune                       0.8.4\n","mizani                        0.8.1\n","mkl                           2019.0\n","ml-dtypes                     0.1.0\n","mlxtend                       0.14.0\n","more-itertools                9.1.0\n","moviepy                       1.0.3\n","mpmath                        1.3.0\n","msgpack                       1.0.5\n","multidict                     6.0.4\n","multipledispatch              0.6.0\n","multitasking                  0.0.11\n","murmurhash                    1.0.9\n","music21                       8.1.0\n","mxnet                         1.9.1\n","natsort                       8.3.1\n","nbclient                      0.7.4\n","nbconvert                     6.5.4\n","nbformat                      5.8.0\n","nest-asyncio                  1.5.6\n","networkx                      3.1\n","nibabel                       3.0.2\n","nltk                          3.8.1\n","notebook                      6.4.8\n","numba                         0.56.4\n","numexpr                       2.8.4\n","numpy                         1.22.4\n","nvidia-cublas-cu11            11.10.3.66\n","nvidia-cuda-cupti-cu11        11.7.101\n","nvidia-cuda-nvrtc-cu11        11.7.99\n","nvidia-cuda-runtime-cu11      11.7.99\n","nvidia-cudnn-cu11             8.5.0.96\n","nvidia-cufft-cu11             10.9.0.58\n","nvidia-curand-cu11            10.2.10.91\n","nvidia-cusolver-cu11          11.4.0.1\n","nvidia-cusparse-cu11          11.7.4.91\n","nvidia-nccl-cu11              2.14.3\n","nvidia-nvtx-cu11              11.7.91\n","oauth2client                  4.1.3\n","oauthlib                      3.2.2\n","opencv-contrib-python         4.7.0.72\n","opencv-python                 4.7.0.72\n","opencv-python-headless        4.7.0.72\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","optax                         0.1.5\n","orbax-checkpoint              0.2.1\n","osqp                          0.6.2.post8\n","packaging                     23.1\n","palettable                    3.3.3\n","pandas                        1.5.3\n","pandas-datareader             0.10.0\n","pandas-gbq                    0.17.9\n","pandocfilters                 1.5.0\n","panel                         0.14.4\n","param                         1.13.0\n","parso                         0.8.3\n","partd                         1.4.0\n","pathlib                       1.0.1\n","pathy                         0.10.1\n","patsy                         0.5.3\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        8.4.0\n","pip                           23.1.2\n","pip-tools                     6.13.0\n","platformdirs                  3.3.0\n","plotly                        5.13.1\n","plotnine                      0.10.1\n","pluggy                        1.0.0\n","polars                        0.17.3\n","pooch                         1.6.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.3\n","preshed                       3.0.8\n","prettytable                   0.7.2\n","proglog                       0.1.10\n","progressbar2                  4.2.0\n","prometheus-client             0.16.0\n","promise                       2.3\n","prompt-toolkit                3.0.38\n","prophet                       1.1.2\n","proto-plus                    1.22.2\n","protobuf                      3.20.3\n","psutil                        5.9.5\n","psycopg2                      2.9.6\n","ptyprocess                    0.7.0\n","py-cpuinfo                    9.0.0\n","py4j                          0.10.9.7\n","pyarrow                       9.0.0\n","pyasn1                        0.5.0\n","pyasn1-modules                0.3.0\n","pycocotools                   2.0.6\n","pycparser                     2.21\n","pyct                          0.5.0\n","pydantic                      1.10.7\n","pydata-google-auth            1.7.0\n","pydot                         1.4.2\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyerfa                        2.0.0.3\n","pygame                        2.3.0\n","Pygments                      2.14.0\n","PyGObject                     3.36.0\n","pymc                          5.1.2\n","PyMeeus                       0.5.12\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.9\n","pyproject_hooks               1.0.0\n","pyrsistent                    0.19.3\n","PySocks                       1.7.1\n","pytensor                      2.10.1\n","pytest                        7.2.2\n","python-apt                    0.0.0\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                8.0.1\n","python-utils                  3.5.2\n","pytorch-lightning             1.2.10\n","pytz                          2022.7.1\n","pytz-deprecation-shim         0.1.0.post0\n","pyviz-comms                   2.2.1\n","PyWavelets                    1.4.1\n","PyYAML                        6.0\n","pyzmq                         23.2.1\n","qdldl                         0.1.7\n","qudida                        0.0.4\n","regex                         2022.10.31\n","requests                      2.27.1\n","requests-oauthlib             1.3.1\n","requests-unixsocket           0.2.0\n","requirements-parser           0.5.0\n","rich                          13.3.4\n","rpy2                          3.5.5\n","rsa                           4.9\n","scikit-image                  0.19.3\n","scikit-learn                  1.2.2\n","scipy                         1.10.1\n","scs                           3.2.3\n","seaborn                       0.12.2\n","Send2Trash                    1.8.0\n","sentencepiece                 0.1.99\n","setuptools                    67.7.2\n","shapely                       2.0.1\n","six                           1.16.0\n","sklearn-pandas                2.2.0\n","smart-open                    6.3.0\n","sniffio                       1.3.0\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soundfile                     0.12.1\n","soupsieve                     2.4.1\n","soxr                          0.3.5\n","spacy                         3.5.2\n","spacy-legacy                  3.0.12\n","spacy-loggers                 1.0.4\n","Sphinx                        3.5.4\n","sphinxcontrib-applehelp       1.0.4\n","sphinxcontrib-devhelp         1.0.2\n","sphinxcontrib-htmlhelp        2.0.1\n","sphinxcontrib-jsmath          1.0.1\n","sphinxcontrib-qthelp          1.0.3\n","sphinxcontrib-serializinghtml 1.1.5\n","SQLAlchemy                    2.0.10\n","sqlparse                      0.4.4\n","srsly                         2.4.6\n","statsmodels                   0.13.5\n","sympy                         1.11.1\n","tables                        3.8.0\n","tabulate                      0.8.10\n","tblib                         1.7.0\n","tenacity                      8.2.2\n","tensorboard                   2.12.2\n","tensorboard-data-server       0.7.0\n","tensorboard-plugin-wit        1.8.1\n","tensorflow                    2.12.0\n","tensorflow-datasets           4.9.2\n","tensorflow-estimator          2.12.0\n","tensorflow-gcs-config         2.12.0\n","tensorflow-hub                0.13.0\n","tensorflow-io-gcs-filesystem  0.32.0\n","tensorflow-metadata           1.13.1\n","tensorflow-probability        0.20.0\n","tensorstore                   0.1.36\n","termcolor                     2.3.0\n","terminado                     0.17.1\n","text-unidecode                1.3\n","textblob                      0.17.1\n","tf-slim                       1.1.0\n","thinc                         8.1.9\n","threadpoolctl                 3.1.0\n","tifffile                      2023.4.12\n","tinycss2                      1.2.1\n","tokenizers                    0.13.3\n","toml                          0.10.2\n","tomli                         2.0.1\n","toolz                         0.12.0\n","torch                         2.0.1\n","torchmetrics                  0.2.0\n","torchsummary                  1.5.1\n","tornado                       6.3.1\n","tqdm                          4.65.0\n","traitlets                     5.7.1\n","transformers                  4.29.2\n","triton                        2.0.0\n","tweepy                        4.13.0\n","typer                         0.7.0\n","types-setuptools              67.7.0.2\n","typing_extensions             4.5.0\n","tzdata                        2023.3\n","tzlocal                       4.3\n","uritemplate                   4.1.1\n","urllib3                       1.26.15\n","vega-datasets                 0.9.0\n","wasabi                        1.1.1\n","wcwidth                       0.2.6\n","webcolors                     1.13\n","webencodings                  0.5.1\n","websocket-client              1.5.1\n","Werkzeug                      2.3.0\n","wheel                         0.40.0\n","widgetsnbextension            3.6.4\n","wordcloud                     1.8.2.2\n","wrapt                         1.14.1\n","xarray                        2022.12.0\n","xarray-einstats               0.5.1\n","xgboost                       1.7.5\n","xlrd                          2.0.1\n","yarl                          1.9.2\n","yellowbrick                   1.5\n","yfinance                      0.2.18\n","zict                          3.0.0\n","zipp                          3.15.0\n"]}]},{"cell_type":"markdown","source":["# Import Library"],"metadata":{"id":"6cn7aITb2vKM"}},{"cell_type":"code","source":["# KoBERT\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","from google.colab import drive\n","\n","# KoGPT\n","import argparse\n","import logging\n","# import numpy as np\n","# import pandas as pd\n","# import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"],"metadata":{"id":"9q6EhmB92RiI","executionInfo":{"status":"ok","timestamp":1684399324331,"user_tz":-540,"elapsed":15337,"user":{"displayName":"김민경","userId":"16965087844038137414"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# BERGPT"],"metadata":{"id":"FxF2UADc3WHj"}},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python 3-BERGPT.py --train --gpus 1 --max_epochs 2"],"metadata":{"id":"EARU2N6m3VXB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684050290702,"user_tz":-540,"elapsed":3521827,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"2d91c760-0f80-49e7-8b4f-c64efa424201"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-14 06:46:14.307503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n","Downloading (…)/main/tokenizer.json: 100% 2.83M/2.83M [00:00<00:00, 6.46MB/s]\n","Downloading (…)lve/main/config.json: 100% 1.00k/1.00k [00:00<00:00, 4.95MB/s]\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","INFO:root:Namespace(chat=False, sentiment='0', keywords='0', model_params='model_chp/model_-last.ckpt', train=True, max_len=32, batch_size=96, lr=5e-05, warmup_ratio=0.1, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=1, auto_select_gpus=False, tpu_cores=None, log_gpu_memory=None, progress_bar_refresh_rate=None, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=2, min_epochs=None, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=None, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False)\n","Downloading pytorch_model.bin: 100% 513M/513M [00:03<00:00, 138MB/s] \n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | kogpt2        | GPT2LMHeadModel  | 125 M \n","1 | loss_function | CrossEntropyLoss | 0     \n","---------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","Epoch 0:   0% 0/1825 [00:00<?, ?it/s] INFO:root:contexts : 이 직업을 왜 하고 싶은지 어떤 성과를 거둘 수 있을지 설득해보셨나요\n","INFO:root:contexts : 이번에 공채 준비하는 데 정보를 얻는 데 있어 너무 어려워\n","INFO:root:toked ctx: ['<usr>', '▁이', '▁직업을', '▁왜', '▁하고', '▁싶은', '지', '▁어떤', '▁성과를', '▁거둘', '▁수', '▁있을', '지', '▁설득', '해보', '셨', '나', '요', '<unused1>', '▁3', '.0', '<unused2>', '▁5', '.0']\n","INFO:root:toked ctx: ['<usr>', '▁이', '번에', '▁공', '채', '▁준비하는', '▁데', '▁정보를', '▁얻는', '▁데', '▁있어', '▁너무', '▁어려워', '<unused1>', '▁2.', '0', '<unused2>', '▁1.0']\n","INFO:root:response : 너 말처럼 조사해서 조리 있게 설득해봐야겠어\n","INFO:root:response : 공채 관련 정보를 얻는 데에 어려움을 많이 느끼시는군요\n","INFO:root:toked response : ['<sys>', '▁공', '채', '▁관련', '▁정보를', '▁얻는', '▁데에', '▁어려움을', '▁많이', '▁느끼', '시는', '군', '요', '</s>']\n","INFO:root:toked response : ['<sys>', '▁너', '▁말', '처럼', '▁조사', '해서', '▁조리', '▁있게']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁공', '채', '▁관련', '▁정보를', '▁얻는', '▁데에', '▁어려움을', '▁많이', '▁느끼', '시는', '군', '요', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁너', '▁말', '처럼', '▁조사', '해서', '▁조리', '▁있게']\n","/content/drive/MyDrive/Workspace/3-BERGPT.py:425: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","/content/drive/MyDrive/Workspace/3-BERGPT.py:425: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","Epoch 0: 100% 1825/1825 [28:46<00:00,  1.06it/s, loss=25.1, v_num=0]Epoch 0, global step 1824: train_loss reached 23.31987 (best 23.31987), saving model to \"/content/drive/MyDrive/Workspace/model_chp/model_-epoch=00-train_loss=23.32.ckpt\" as top 1\n","Epoch 1:   0% 0/1825 [00:00<?, ?it/s, loss=25.1, v_num=0]INFO:root:contexts : 나 자꾸만 조바심이 들어\n","INFO:root:toked ctx: ['<usr>', '▁나', '▁자', '꾸', '만', '▁조', '바', '심이', '▁들어', '<unused1>', '▁0', '.0', '<unused2>', '▁4', '.0']\n","INFO:root:response : 무슨 일인지 더 얘기해 주실 수 있나요\n","INFO:root:toked response : ['<sys>', '▁무슨', '▁일', '인지', '▁더', '▁얘', '기', '해', '▁주', '실', '▁수', '▁있', '나', '요', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁무슨', '▁일', '인지', '▁더', '▁얘', '기', '해', '▁주', '실', '▁수', '▁있', '나', '요', '</s>']\n","INFO:root:contexts : 학교에 가고 싶지 않을 만큼 두렵군요 숙제도 안하고 수업도 빼먹는 것보단 수업을 가는 것이 낫지 않을까요\n","INFO:root:toked ctx: ['▁것', '보', '단', '▁수업을', '▁가는', '▁것이', '▁낫', '지', '▁않을까', '요', '<unused1>', '▁2.', '0', '<unused2>', '▁5', '.0']\n","INFO:root:response : 그래 수업까지 빼먹으면 더 크게 혼날 거야 학교에 가야겠다\n","INFO:root:toked response : ['<sys>', '▁그래', '▁수업', '까지', '▁빼', '먹', '으면', '▁더', '▁크게', '▁혼', '날', '▁거', '야', '▁학교에', '▁가야', '겠']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁그래', '▁수업', '까지', '▁빼', '먹', '으면', '▁더', '▁크게', '▁혼', '날', '▁거', '야', '▁학교에', '▁가야', '겠']\n","/content/drive/MyDrive/Workspace/3-BERGPT.py:425: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","/content/drive/MyDrive/Workspace/3-BERGPT.py:425: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","Epoch 1: 100% 1825/1825 [28:49<00:00,  1.05it/s, loss=24.7, v_num=0]Epoch 1, step 3649: train_loss was not in top 1\n","Epoch 1: 100% 1825/1825 [29:02<00:00,  1.05it/s, loss=24.7, v_num=0]Saving latest checkpoint...\n","Epoch 1: 100% 1825/1825 [29:03<00:00,  1.05it/s, loss=24.7, v_num=0]\n","INFO:root:best model path /content/drive/MyDrive/Workspace/model_chp/model_-epoch=00-train_loss=23.32.ckpt\n"]}]},{"cell_type":"markdown","source":["# Chat"],"metadata":{"id":"wc_WgmFKCKAN"}},{"cell_type":"code","source":["# 대화 테스트, `quit`를 입력하면 대화 종료\n","!CUDA_VISIBLE_DEVICES=0 python 3-BERGPT.py --gpus 1 --chat"],"metadata":{"id":"PCDPCrhu3-Eh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684399831138,"user_tz":-540,"elapsed":185370,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"21f40907-3b45-4892-b5c0-d97d92e8dcd1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-18 08:47:29.125469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","INFO:root:Namespace(chat=True, sentiment='0', keywords='0', model_params='model_chp/model_-last.ckpt', train=False, max_len=32, batch_size=96, lr=5e-05, warmup_ratio=0.1, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=1, auto_select_gpus=False, tpu_cores=None, log_gpu_memory=None, progress_bar_refresh_rate=None, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=None, min_epochs=None, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=None, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False)\n","user > Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 444, in chat\n","    q = input('user > ').strip()\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 490, in <module>\n","    model.chat()\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 444, in chat\n","    q = input('user > ').strip()\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0 python 3-BERGPT.py --gpus 1 --chat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQttJGXcOO3D","executionInfo":{"status":"ok","timestamp":1684050875778,"user_tz":-540,"elapsed":321220,"user":{"displayName":"김민경","userId":"16965087844038137414"}},"outputId":"94a3f4eb-5dc6-43f5-e6b2-349952dcf8bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-14 07:49:20.405093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","INFO:root:Namespace(chat=True, sentiment='0', keywords='0', model_params='model_chp/model_-last.ckpt', train=False, max_len=32, batch_size=96, lr=5e-05, warmup_ratio=0.1, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=1, auto_select_gpus=False, tpu_cores=None, log_gpu_memory=None, progress_bar_refresh_rate=None, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=None, min_epochs=None, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=None, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False)\n","user > 특별한 이유가 없는데 그냥 불안하고 눈물이 나와.\n","Simsimi > 불안하고 눈물이 나는군요\n","user > 이 세상에서 완전히 사라지고 싶어.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 세상에 완전히 사라지고 싶으시군요\n","user > 가슴이 답답해서 터질 것만 같아요.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 어떻게 해야 이 상황을 해결할 수 있을까요\n","user > 자존감이 낮아지는 것 같아.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 자존감이 낮아지는 것 같아요\n","user > 뭘 해도 금방 지쳐.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 무슨 일이 있으셨나요\n","user > 친구한테 진짜 크게 배신 당했어.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 친구한테 배신당해서 마음이 안 좋으시겠어요\n","user > 내일 진짜 크게 배신 당했어.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Simsimi > 배신당한 기분이시군요\n","user > 내일 놀이공원 갈 건데 사람 별로 없었으면 좋겠다.\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",".\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 490, in <module>\n","    model.chat()\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 453, in chat\n","    pred = self(input_ids)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/MyDrive/Workspace/3-BERGPT.py\", line 387, in forward\n","    output = self.kogpt2(inputs, return_dict=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1076, in forward\n","    transformer_outputs = self.transformer(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 900, in forward\n","    outputs = block(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 390, in forward\n","    attn_outputs = self.attn(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 312, in forward\n","    query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\", line 102, in forward\n","    x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n","KeyboardInterrupt\n","^C\n"]}]}]}